# Model designed using Google Colab 

# Imports
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers, models
from tensorflow.keras.preprocessing.image import ImageDataGenerator as IDG
from tensorflow.keras.layers import Conv2D, Flatten, MaxPooling2D, Dense, Dropout, InputLayer

# Defining global seed for reproducability
SEED = 42
np.random.seed(SEED)
keras.utils.set_random_seed(SEED)
#------------------------------------------------------------------------------------------------------------------------------------
# Step 1: Data Processing

# Defining Input Image Shape (500,500,3), batch size and epochs
img_h = 500
img_w = 500
img_channel = 3 # RGB Channels
img_shape = (img_h,img_w,img_channel)
batch = 32
epoch = 10

# Unzip the file
!unzip -q "/content/Project 2 Data.zip" -d "/content/Project 2 Data"

# Defining relative directory paths
train_directory = "Project 2 Data/Data/train"
valid_directory = "Project 2 Data/Data/valid"


# Data Augmentation on training image set using ImageDataGenerator
train_aug = IDG(
    rotation_range = 10, #random rotation in the range +-10 degrees
    zoom_range = 0.15, #zoom in/out by +-15%
    shear_range = 0.2, #shear angle in degrees
    brightness_range = [0.85,1.15], # +-15% variation in brightness
    rescale = 1./255, #normalize RGB pixels from [0,255] into [0,1]
    fill_mode = "nearest",
    horizontal_flip = True #flip images horizontally
)

# Validation images only rescaled since those would be used to validate our training effectiveness so augmentation is unnecessary
valid_aug = IDG(
    rescale = 1./255)

# Data Generator using ImageDataGenerator
train_gen = train_aug.flow_from_directory(
    train_directory,
    target_size=(img_h,img_w),
    color_mode = 'rgb',
    classes = ['crack','missing-head','paint-off'],
    class_mode = 'categorical',
    batch_size = batch,
    shuffle = True, # Shuffles training sample for better generalization learning
    seed = SEED
)

valid_gen = valid_aug.flow_from_directory(
    valid_directory,
    target_size=(img_h,img_w),
    color_mode = 'rgb',
    classes = ['crack','missing-head','paint-off'],
    class_mode = 'categorical',
    batch_size = batch,
    shuffle = False,
    seed = SEED
)

# Sanity Checks to ensure all image samples are being processed and classes are correctly inferred
print("\nTrain generator:", train_gen.samples, "samples")
print("Validation generator:", valid_gen.samples, "samples")
print("Train Class indices:", train_gen.class_indices)
#------------------------------------------------------------------------------------------------------------------------------------
# Step 2-3: Nueral Network Architecture and Hyperparameter Tuning

early_stop = keras.callbacks.EarlyStopping(
    monitor="val_accuracy",
    patience=3,
    restore_best_weights=True
)

mdl1 = models.Sequential()
mdl1.add(InputLayer(shape=img_shape))
mdl1.add(Conv2D(32, (3,3), strides= 2, activation="leaky_relu"))
mdl1.add(MaxPooling2D(2,2))
mdl1.add(Conv2D(64, (3,3), activation="leaky_relu"))
mdl1.add(MaxPooling2D(2,2))
mdl1.add(Conv2D(128, (3,3), activation="leaky_relu"))
mdl1.add(MaxPooling2D(2,2))
mdl1.add(Flatten()) # Flattening layer transforming all pixel data into a single vector
mdl1.add(Dense(64, activation="elu")) # 64 neurons in hidden layer
mdl1.add(Dropout(0.2)) # Dropping 20% of activation from previous layer
mdl1.add(Dense(3, activation="softmax")) # Output layer with 3 neurons for 3 output classes

mdl2 = models.Sequential()
mdl2.add(InputLayer(shape=img_shape))
mdl2.add(Conv2D(32, (5,5), activation="relu"))
mdl2.add(MaxPooling2D(2,2))
mdl2.add(Conv2D(64, (3,3), activation="relu"))
mdl2.add(MaxPooling2D(2,2))
mdl2.add(Conv2D(128, (3,3), activation="relu"))
mdl2.add(MaxPooling2D(2,2))
mdl2.add(Flatten()) # Flattening layer transforming all pixel data into a single vector
mdl2.add(Dense(32, activation="relu")) # 64 neurons in hidden layer w/ elu
mdl2.add(Dropout(0.3)) # Dropping 30% of activation from previous layer
mdl2.add(Dense(3, activation="softmax")) # Output layer with 3 neurons for 3 output classes


# Optimizers
mdl1.compile(
    optimizer=keras.optimizers.Adam(learning_rate=1e-3),
    loss="categorical_crossentropy",
    metrics=['accuracy']
)
mdl2.compile(
    optimizer=keras.optimizers.RMSprop(learning_rate=1e-3),
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

# Print Model summary for each layer
mdl1.summary()
mdl2.summary()

history1 = mdl1.fit(
    train_gen,
    validation_data = valid_gen,
    epochs= epoch,
    batch_size= batch,
    callbacks=[early_stop],
    verbose=1
)

history2 = mdl2.fit(
    train_gen,
    validation_data = valid_gen,
    epochs= epoch,
    batch_size= batch,
    callbacks=[early_stop],
    verbose=1
)
#------------------------------------------------------------------------------------------------------------------------------------
# Step 4: Model Evaluation

val_loss, val_accuracy = mdl1.evaluate(valid_gen)
print(f"\nFinal Validation accuracy: {val_accuracy:.4f}")
print(f"Final Validation loss: {val_loss:.4f}\n")

# Access training loss and accuracy
train_loss = history1.history['loss'][-1]
train_accuracy = history1.history['accuracy'][-1]
print(f"\nFinal Training accuracy: {train_accuracy:.4f}")
print(f"Final Training loss: {train_loss:.4f}\n")

# Training & Validation accuracy plot size
plt.figure(figsize=(15, 5))

# Plotting training & Validation accuracy
plt.plot(history1.history['accuracy'], label="Training Accuracy")
plt.plot(history1.history['val_accuracy'], label="Validation Accuracy")
plt.title('Model Training and Validation Accuracy')
plt.xlabel("Epoch")
plt.ylabel("Accuracy")
plt.legend()

# Training & Validation loss plot size
plt.figure(figsize=(15, 5))

# Plotting Training and Validation loss
plt.plot(history1.history['loss'], label="Training Loss")
plt.plot(history1.history['val_loss'], label="Validation Loss")
plt.title('Model Training and Validation Loss')
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.legend()

